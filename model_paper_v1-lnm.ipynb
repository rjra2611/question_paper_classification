{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from scipy import spatial\n",
    "import requests\n",
    "import os \n",
    "from os.path import getsize\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pytesseract\n",
    "import tempfile\n",
    "from pdf2image import convert_from_path, convert_from_bytes\n",
    "import PyPDF2\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from spacy.matcher import PhraseMatcher\n",
    "import re\n",
    "import string\n",
    "import pickle\n",
    "from PIL import Image\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to check if the token is a noise or not  \n",
    "def isNoise(token):  \n",
    "    noisy_pos_tags = ['PROP']\n",
    "    min_token_length = 2\n",
    "\n",
    "    is_noise = False\n",
    "    if token.pos_ in noisy_pos_tags:\n",
    "        is_noise = True \n",
    "    elif token.is_stop == True:\n",
    "        is_noise = True\n",
    "    elif len(token.string) <= min_token_length:\n",
    "        is_noise = True\n",
    "    return is_noise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(token, lower = True):\n",
    "    if lower:\n",
    "        token = token.lower()\n",
    "    return token.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(nlp_document, Is_lower_true=True):\n",
    "    cleaned_list = [cleanup(word.string,Is_lower_true) for word in nlp_document if not isNoise(word)]\n",
    "    return ' '.join(cleaned_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initials(fullname):\n",
    "  xs = (fullname)\n",
    "  name_list = xs.split()\n",
    "\n",
    "  initials = \"\"\n",
    "\n",
    "  for name in name_list:  # go through each name\n",
    "    initials += name[0].upper()  # append the initial\n",
    "\n",
    "  return initials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"./ec list.xlsx\")\n",
    "# df.to_excel(\"./ec list.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_san = pd.read_csv('./ece_questions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_san.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_san = df_san.drop(labels = 'Unnamed: 0', axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product = list(df_san.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_san.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['id'] = list(range(37))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = list(df_new['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_new.iloc[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for i in range(df_new.shape[0]):\n",
    "    X.append(list(df_new.iloc[i,:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(data=X[0],columns=['quesions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list=[]\n",
    "for i in range(len(X)):\n",
    "    df_list.append(pd.DataFrame(data=X[i],columns=['questions']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_list)):\n",
    "    df_list[i]['id']=product[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_san.to_csv('./ece_questions_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ece_ques= df_san.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(ece_ques.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = list(ece_ques.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['CLEAN_DATA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['DISCIPLINE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(y)):\n",
    "    y[i] = y[i].upper().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import randint\n",
    "import seaborn as sns # used for plot interactive graph. \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from io import StringIO\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df1['COLLEGE ']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in y:\n",
    "    print(type(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe with two columns\n",
    "df1 = df_concat[['questions', 'id']].copy()\n",
    "\n",
    "# Remove missing values (NaN)\n",
    "df1 = df1[pd.notnull(df1['questions'])]\n",
    "\n",
    "# Renaming second column for a simpler name\n",
    "df1.columns = ['X', 'Y'] \n",
    "\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df1.Y.unique()).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.columns = [ 'Consumer_complaint','Product'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_clean = list(df2['Consumer_complaint'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_clean = [clean_data(nlp(f)) for f in to_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Consumer_complaint'] = to_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['category_id'] = df2['Product'].factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['category_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_id_df = df2[['Product', 'category_id']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_id_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_11 = df2['category_id']!=11 \n",
    "is_12 = df2['category_id']!=12\n",
    "is_9 = df2['category_id']!=9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in a:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2[is_9]\n",
    "df2 = df2[is_11]\n",
    "df2 = df2[is_12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionaries for future use\n",
    "category_to_id = dict(category_id_df.values)\n",
    "id_to_category = dict(category_id_df[['category_id', 'Product']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "colors = ['grey','grey','grey','grey','grey','grey','grey','grey','grey',\n",
    "    'grey','darkblue','darkblue','darkblue']\n",
    "df2.groupby('Product').Consumer_complaint.count().sort_values().plot.barh(\n",
    "    ylim=0, color=colors, title= 'NUMBER OF COMPLAINTS IN EACH PRODUCT CATEGORY\\n')\n",
    "plt.xlabel('Number of ocurrences', fontsize = 10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5,\n",
    "                        ngram_range=(1, 2), \n",
    "                        stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tfidf.fit_transform(df2.Consumer_complaint).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df2.category_id\n",
    "\n",
    "print(\"Each of the %d complaints is represented by %d features (TF-IDF score of unigrams and bigrams)\" %(features.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the three most correlated terms with each of the product categories\n",
    "N = 7\n",
    "for Product, category_id in sorted(category_to_id.items()):\n",
    "  features_chi2 = chi2(features, labels == category_id)\n",
    "  indices = np.argsort(features_chi2[0])\n",
    "  feature_names = np.array(tfidf.get_feature_names())[indices]\n",
    "  unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n",
    "  bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n",
    "  print(\"\\n==> %s:\" %(Product))\n",
    "  print(\"  * Most Correlated Unigrams are: %s\" %(', '.join(unigrams[-N:])))\n",
    "  print(\"  * Most Correlated Bigrams are: %s\" %(', '.join(bigrams[-N:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2['Consumer_complaint'] # Collection of documents\n",
    "y = df2['Product'] # Target or the labels we want to predict (i.e., the 13 different complaints of products)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = [\n",
    "#     RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0),\n",
    "#     LinearSVC(),\n",
    "#     MultinomialNB(),\n",
    "#     LogisticRegression(random_state=0)]\n",
    "\n",
    "models = [\n",
    "    LinearSVC(),\n",
    "    MultinomialNB()]\n",
    "\n",
    "# 5 Cross-validation\n",
    "CV = 5\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "\n",
    "entries = []\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    accuracies = cross_val_score(model, features, labels, scoring='accuracy', cv=CV)\n",
    "    for fold_idx, accuracy in enumerate(accuracies):\n",
    "        entries.append((model_name, fold_idx, accuracy))\n",
    "    \n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])\n",
    "print(cv_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_accuracy = cv_df.groupby('model_name').accuracy.mean()\n",
    "std_accuracy = cv_df.groupby('model_name').accuracy.std()\n",
    "\n",
    "acc = pd.concat([mean_accuracy, std_accuracy], axis= 1, \n",
    "          ignore_index=True)\n",
    "acc.columns = ['Mean Accuracy', 'Standard deviation']\n",
    "acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "sns.boxplot(x='model_name', y='accuracy', \n",
    "            data=cv_df, \n",
    "            color='lightblue', \n",
    "            showmeans=True)\n",
    "plt.title(\"MEAN ACCURACY (cv = 5)\\n\", size=14);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test,indices_train,indices_test = train_test_split(features, \n",
    "                                                               labels, \n",
    "                                                               df2.index, test_size=0.25, \n",
    "                                                               random_state=1)\n",
    "model = LinearSVC()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print('\\t\\t\\t\\tCLASSIFICATIION METRICS\\n')\n",
    "print(metrics.classification_report(y_test, y_pred, \n",
    "                                    target_names=['ap','cn', 'coa','cp','dsa','dsy', 'opp', 'idbms','ota','daa','os']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "sns.heatmap(conf_mat, annot=True, cmap=\"Blues\", fmt='d',\n",
    "            xticklabels=category_id_df.Product.values, \n",
    "            yticklabels=category_id_df.Product.values)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title(\"CONFUSION MATRIX - LinearSVC\\n\", size=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for predicted in category_id_df.category_id:\n",
    "  for actual in category_id_df.category_id:\n",
    "    if predicted != actual and conf_mat[actual, predicted] >= 20:\n",
    "      print(\"'{}' predicted as '{}' : {} examples.\".format(id_to_category[actual], \n",
    "                                                           id_to_category[predicted], \n",
    "                                                           conf_mat[actual, predicted]))\n",
    "    \n",
    "      display(df2.loc[indices_test[(y_test == actual) & (y_pred == predicted)]][['Product', \n",
    "                                                                'Consumer_complaint']])\n",
    "      print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(features, labels)\n",
    "\n",
    "N = 4\n",
    "for Product, category_id in sorted(category_to_id.items()):\n",
    "  indices = np.argsort(model.coef_[category_id])\n",
    "  feature_names = np.array(tfidf.get_feature_names())[indices]\n",
    "  unigrams = [v for v in reversed(feature_names) if len(v.split(' ')) == 1][:N]\n",
    "  bigrams = [v for v in reversed(feature_names) if len(v.split(' ')) == 2][:N]\n",
    "  print(\"\\n==> '{}':\".format(Product))\n",
    "  print(\"  * Top unigrams: %s\" %(', '.join(unigrams)))\n",
    "  print(\"  * Top bigrams: %s\" %(', '.join(bigrams)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state = 0)\n",
    "\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5,\n",
    "                        ngram_range=(1, 2), \n",
    "                        stop_words='english')\n",
    "\n",
    "fitted_vectorizer = tfidf.fit(X_train)\n",
    "tfidf_vectorizer_vectors = fitted_vectorizer.transform(X_train)\n",
    "\n",
    "model = LinearSVC().fit(tfidf_vectorizer_vectors, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
